{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc651e2a",
   "metadata": {},
   "source": [
    "# Análisis de los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3321597a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.0-cp310-cp310-macosx_10_9_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.7.0 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from gensim) (1.22.3)\n",
      "Collecting FuzzyTM>=0.4.0\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from gensim) (6.3.0)\n",
      "Collecting pyfume\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from FuzzyTM>=0.4.0->gensim) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.1)\n",
      "Collecting fst-pso\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting simpful\n",
      "  Downloading simpful-2.9.0-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Collecting miniful\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.26.11)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20431 sha256=6cc3f83db041031068ad4b591b6a4d2c5ec8468c9ba373914f42e933e131f5b5\n",
      "  Stored in directory: /Users/rosalermaguerrero/Library/Caches/pip/wheels/2d/1b/42/88a19f6b3896c2230d5053832f208976cddf70625885201d06\n",
      "  Building wheel for miniful (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3514 sha256=296e005252898ba6b09f86b1967b92e96759bde2467b2c5d7eca722669bdbe41\n",
      "  Stored in directory: /Users/rosalermaguerrero/Library/Caches/pip/wheels/5b/86/8f/7bb7f6472e2c84de7addfc1a5cd7fd647f00d8fb640da9ea9a\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: simpful, miniful, fst-pso, pyfume, FuzzyTM, gensim\n",
      "Successfully installed FuzzyTM-2.0.5 fst-pso-1.8.1 gensim-4.3.0 miniful-0.0.6 pyfume-0.2.25 simpful-2.9.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "065c3fd0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.4.0-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pyLDAvis) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pyLDAvis) (1.2.1)\n",
      "Requirement already satisfied: numexpr in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pyLDAvis) (2.8.1)\n",
      "Collecting funcy\n",
      "  Downloading funcy-1.18-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pyLDAvis) (1.22.3)\n",
      "Requirement already satisfied: gensim in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pyLDAvis) (4.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pyLDAvis) (63.4.1)\n",
      "Requirement already satisfied: scipy in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pyLDAvis) (1.7.3)\n",
      "Requirement already satisfied: pandas>=1.3.4 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pyLDAvis) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pandas>=1.3.4->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pandas>=1.3.4->pyLDAvis) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from scikit-learn>=1.0.0->pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from gensim->pyLDAvis) (2.0.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from gensim->pyLDAvis) (6.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from jinja2->pyLDAvis) (2.1.1)\n",
      "Requirement already satisfied: packaging in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Requirement already satisfied: pyfume in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from FuzzyTM>=0.4.0->gensim->pyLDAvis) (0.2.25)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.3.4->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n",
      "Requirement already satisfied: fst-pso in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (1.8.1)\n",
      "Requirement already satisfied: simpful in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (2.9.0)\n",
      "Requirement already satisfied: miniful in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (0.0.6)\n",
      "Requirement already satisfied: requests in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rosalermaguerrero/opt/anaconda3/envs/general/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (3.3)\n",
      "Installing collected packages: funcy, pyLDAvis\n",
      "Successfully installed funcy-1.18 pyLDAvis-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "125599c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosalermaguerrero/Desktop/BOOTCAMP/ML PROYECTO/datafunction/edit_text.py:14: DeprecationWarning: invalid escape sequence '\\.'\n",
      "  REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\“)|(\\”)|(\\')|(\\»)|(\\«)|(\\()|(\\))|(\\[)|(\\])|(\\d+)|(\\¿)|(\\¡)|(\\%)\")\n",
      "/Users/rosalermaguerrero/Desktop/BOOTCAMP/ML PROYECTO/datafunction/edit_text.py:15: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  REPLACE_WITH_SPACE = re.compile(\"(<br \\s*/><br\\s*/>)|(\\-)|(\\/)\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from datafunction import edit_text \n",
    "\n",
    "# LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# SPACY\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "\n",
    "# NLP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Visaulización \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8e0a8a5b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'el acoso callejero es la forma de violencia de género más normalizada desde el acoso verbal al acoso con contacto físico se trata de un problema diario al que se han enfrentado alguna vez casi de cada jóvenes de barcelona madrid y sevillaesta es una de las conclusiones a las que ha llegado el estudio safer cities for girls elaborado por plan international ong de ayuda a la infancia a lo largo de y adolescentes y mujeres jóvenes de diferentes ciudades europeas han compartido sus experiencias en las calles dando como resultado diferentes informes la ciudad madrileña de alcobendas ha sido la protagonista del proyecto alcobendas ciudad más segura elaborado por la ong tras reunir experiencias diferentes todas de jóvenes habitantes del municipio el estudio ha logrado extraer datos claros que ayudan a comprender la situación del acoso callejero a las mujeres isabel de años es una de las jóvenes que ha participado en el estudio de alcobendas ella ha vivido situaciones de acoso callejero en su vida diaria y su experiencia ayuda a comprender un poco mejor cómo dónde y por qué suceden estas agresiones las situaciones de inseguridad recogidas por el estudio se dieron mayoritariamente en la calle en un de los casos y en parques y jardines en un de los casos en un de los casos estas situaciones ocurrían de madrugada o en cualquier momento del día pero isabel cuenta que aunque esta sea la creencia generalizada el acoso no solo ocurre de noche y en zonas peligrosascuando entré en safer tenía claro que esto pasaba en calles poco luminosas sitios con bares… pero al hablarlo con otras chicas me he dado cuenta de que no por las mañanas cerca del metro me ha llegado a pasar y pienso son las ocho de la mañana hay suficiente luz y gente como para que esto no tenga que estar pasando nos pasa en calles con mucha gente pasa a plena luz del día con gente que lo está escuchando cuenta la joven que ha participado en el estudio llevado a cabo por plan internacional en cuanto a quién lleva a cabo estos actos en el de las experiencias las jóvenes señalan que se trataba de un hombre y en el los acosadores eran un grupo de hombresel diseño urbanístico de nuestras ciudades es un factor clave para determinar la seguridad unas infraestructuras adecuadas y la presencia de policía o vigilancia son claves para las jóvenes víctimas de acoso en las calles hay varios aspectos que determinan si un espacio transmite o no seguridad la iluminación es una de ellas aunque la presencia de gente es lo que más predomina las zonas en las que menos inseguras nos sentimos son zonas por ejemplo con bares pero bares con familias calles con comercios enumera isabel el proyecto safer cities for girls reunió al grupo de discusión formado por jóvenes que han sufrido situaciones de acoso callejero con el alcalde de alcobendas para plantearle ciertos cambios necesarios para aumentar la seguridad el sentimiento de indefensión es común en muchas de las víctimas a pesar de que por definición las situaciones de acoso callejero ocurren en espacios públicos son pocas las veces en las que los viandantes que lo presencian se ofrecen a ayudar según la encuesta el de las jóvenes no recibieron ayuda de testigos de la situación de acoso y solamente el sí lo hicieron isabel también ha vivido situaciones de este tipo me ha pasado que gente que lo estaba escuchando luego se acercaba a decirte pobre que pena que hayas tenido que pasar por eso y por qué en el momento en el que está pasando no dices nadalas situaciones de acoso callejero han llegado a estar normalizadas tanto que las jóvenes víctimas de gritos piropos o comentarios sexuales terminan por no reaccionar ante este ataque al principio me cabreaba muchísimo pero no sabía cómo reaccionar pensaba qué hago grito me enfado monto una escena en medio de la calle luego con los años ha sido más indiferencia pero no me parece que esté bien porque no lo quiero normalizar pero al final pasaba y pensaba ya está sigo con mi vida confiesa la joven participante en el estudiola vergüenza y la normalización de situaciones como esta provoca el silencio en las víctimas tras el episodio de acoso un de las jóvenes encuestadas se lo contó a familiares y amigos hasta un de las encuestadas reconoce no hacer nada porque como le ocurre a isabel es tan rutinario que ya no lo ves como algo llamativoel objetivo de este proyecto de plan international no es solo concienciar a la población sino también crear un espacio seguro entre las adolescentes que lo han sufrido un ambiente en el que puedan hablar sobre lo ocurrido y compartir sus experiencias safer me ayudó porque nos sentamos a hablar de cosas que yo en mi día a día no hablaba porque daba por hecho que eran normales cuenta isabellos resultados de esta encuesta dejan claro que las jóvenes víctimas de acoso callejero desconfían en general de las fuerzas policiales también muestra un desconocimiento generalizado sobre la legislación que protege ante estas situaciones plan international llevó a cabo una entrevista al grupo luna grupo especial de la policía local de alcobendas dedicado a la violencia de género desde este grupo policial señalan que el acoso callejero es algo que queda fuera de sus competencias y que solo pueden actuar cuando es violencia en el marco de la pareja o exparejael momento de denunciar una situación de acoso ante las autoridades también genera rechazo en las adolescentes que han vivido una situación de acoso al final la conclusión a la que llegábamos es que no sabíamos si nos merecía la pena comenta la joven de alcobendas que cuenta que conocidas de su alrededor han tratado de denunciar y se han encontrado con el juicio de la policía al llegar allí te encuentras con ciertas preguntas que te dan la sensación de que la que estás haciendo las cosas mal eres tú al final el acoso se presentaba como un castigo divino que te toca porque has hecho algo mal por ejemplo llevar una falda al final la gente que lo ha sufrido no lo ha denunciado afirma isabel no obstante la joven afirma que la presencia policial es algo importante para mantener la seguridad de las mujeres en las calles aunque no nos sintamos del todo cómodas contando nuestra experiencia es verdad que la presencia policial ayuda porque al final las otras personas sienten que si está ahí la policía no pueden hacerte nadaqué consecuencias tiene el acoso en la vida de las mujeres que lo han sufrido los cambios en la rutina en la forma de vestir o en incluso en las rutas por las que se camina son frecuentes según los datos de plan international el de las jóvenes encuestadas nunca ha regresado sola al lugar donde vivió alguna experiencia de inseguridad o de acoso y el ha buscado caminos alternativos para no pasar por ese lugarestos cambios no suelen ser conscientes o voluntarios sino que surgen a raíz de un miedo que se instala en la mente de las víctimas han sido cambios pequeños y subconscientes que tú misma a veces no te das cuenta de que lo has cambiado cuenta isabel por ejemplo he cambiado las zonas sitios por los que antes pasaba sola sin problema pero si ya me han gritado me han dicho algo o me han hecho un mal llamado piropo ya las evito no lo hago conscientemente pero mi cabeza dice aquí te van a decir algo mejor ve por otra calle y también me pasa en la ropa hay mucha ropa que ya no me pongolas consecuencias de vivir una situación de acoso sexual en las calles también son psicológicas impotencia vulnerabilidad inseguridad molestia miedo sentimiento de invasión o vergüenza son algunos de los sentimientos que una situación de este calibre puede producir en las víctimas según un estudio llevado a cabo por la universidad autónoma de yucatánciertas cosas deben cambiar para que esto no siga ocurriendo la educación asegura isabel es una de las pocas cosas que lo pueden prevenir si educamos desde muy pequeños igual que educamos en llevar las llaves o tener cuidado en ciertas calles probablemente las generaciones futuras empiecen a entenderlo de otra forma y empiecen a vivirlo de otra manera opina la jovenisabel asegura que le gustaría que ninguna más sintiera culpabilidad después de una situación de acoso creo que mi forma de reaccionar cambiará me gustaría entender que la culpa no es mía que no puedo hacer nada para evitarlo que la pelota está en el otro lado la joven asegura que si pudiera dar un consejo a una chica a la que le haya ocurrido una situación similar le diría que no tiene nada de culpa realmente da igual lo que hubieses hecho da igual si hubieses ido completamente desnuda o completamente vestida no es eso lo que les importa a la hora de acosarte isabel invita a las víctimas a hablar sobre el tema a pedir ayuda siempre que se dé un caso similar acudiendo si es necesario a recursos como los puntos violetas existen un montón de recursos que no somos conscientes de que tenemos tanto online como presenciales si la persona que está leyendo esto lo ha sufrido y quiere hablar de ello que busque esos recursos que no tienen que ser únicamente por las vías oficiales también es importante apoyarnos en otras personas y hablar sobre el temaquieres recibir gratis todos los jueves en tu correo los mejores contenidos de belleza moda y estilo de vida apúntate a nuestra newsletter'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_text.abrir_text(\"TEXTOS\", \"articulo1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6292a1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>textos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>el acoso callejero es la forma de violencia de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>un día cualquiera en la redacción estamos haci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>el día jueves de mayo de mientras iba camino a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>salí de fiesta con mis amigos de la universida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>caminando por la vereda giro para mirar algo q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             textos\n",
       "0      0  el acoso callejero es la forma de violencia de...\n",
       "1      1  un día cualquiera en la redacción estamos haci...\n",
       "2      2  el día jueves de mayo de mientras iba camino a...\n",
       "3      3  salí de fiesta con mis amigos de la universida...\n",
       "4      4  caminando por la vereda giro para mirar algo q..."
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv(\"all_text.csv\")\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6972045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "texts = df_all[\"textos\"]\n",
    "\n",
    "my_stop_words = {\"empezar\", \"micro\", \"año\", \"tipo\"}\n",
    "\n",
    "# Agregar las palabras vacías personalizadas a la lista existente de palabras vacías en español\n",
    "stop_words = STOP_WORDS.union(my_stop_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "29fa935f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.011*\"acoso\" + 0.008*\"sexual\" + 0.007*\"policía\" + 0.007*\"persona\" + 0.006*\"pasar\" + 0.006*\"situación\" + 0.005*\"casa\" + 0.004*\"callejero\" + 0.004*\"nacional\" + 0.004*\"mujer\"')\n",
      "(1, '0.015*\"persona\" + 0.014*\"situación\" + 0.013*\"emergencia\" + 0.010*\"ayuda\" + 0.008*\"información\" + 0.006*\"población\" + 0.006*\"psicológico\" + 0.005*\"riesgo\" + 0.005*\"problema\" + 0.005*\"psicólogo\"')\n",
      "(2, '0.006*\"persona\" + 0.005*\"mujer\" + 0.004*\"casa\" + 0.004*\"emergencia\" + 0.004*\"llegar\" + 0.004*\"relato\" + 0.004*\"situación\" + 0.004*\"ayuda\" + 0.004*\"calle\" + 0.004*\"salir\"')\n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "texts = df_all[\"textos\"]\n",
    "\n",
    "my_stop_words = {\"ir\", \"empezar\", \"micro\", \"año\", \"tipo\", \"empezar\"}\n",
    "\n",
    "# Agregar las palabras vacías personalizadas a la lista existente de palabras vacías en español\n",
    "stop_words = STOP_WORDS.union(my_stop_words)\n",
    "\n",
    "# Cargar el modelo de idioma español en spaCy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return [lemma for lemma in lemmas if lemma not in stop_words]\n",
    "\n",
    "# Aplicar la función de preprocesamiento a cada documento en la lista de documentos\n",
    "docs = [preprocess(doc) for doc in texts]\n",
    "\n",
    "# Crear el diccionario y el corpus\n",
    "dictionary = gensim.corpora.Dictionary(docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Entrenar el modelo LDA con 5 temas\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=3, id2word=dictionary, passes=10)\n",
    "\n",
    "# Imprimir los 5 temas, cada uno con 10 palabras\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a7bd0c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rosalermaguerrero/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rosalermaguerrero/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico: 0 \n",
      "Palabras clave: 0.001*\"camino\" + 0.001*\"seguir\" + 0.001*\"esperar\" + 0.001*\"calle\" + 0.001*\"decir\" + 0.001*\"acercar\" + 0.001*\"llevar\" + 0.001*\"tipo\" + 0.001*\"estar\" + 0.001*\"responder\" + 0.001*\"empezó\" + 0.001*\"hombre\" + 0.001*\"edad\" + 0.001*\"pasar\" + 0.001*\"poder\"\n",
      "\n",
      "Tópico: 1 \n",
      "Palabras clave: 0.001*\"persona\" + 0.001*\"personas\" + 0.001*\"situación\" + 0.001*\"tipo\" + 0.001*\"momento\" + 0.001*\"forma\" + 0.001*\"ver\" + 0.001*\"evitar\" + 0.001*\"situaciones\" + 0.001*\"lugar\" + 0.001*\"poder\" + 0.001*\"profesional\" + 0.001*\"necesario\" + 0.001*\"tener\" + 0.001*\"llegar\"\n",
      "\n",
      "Tópico: 2 \n",
      "Palabras clave: 0.001*\"persona\" + 0.001*\"situación\" + 0.001*\"personas\" + 0.001*\"pensar\" + 0.001*\"ayuda\" + 0.001*\"estar\" + 0.001*\"lugar\" + 0.001*\"alguien\" + 0.001*\"víctima\" + 0.001*\"forma\" + 0.001*\"vivir\" + 0.001*\"cerca\" + 0.001*\"ayudar\" + 0.001*\"hacer\" + 0.001*\"vida\"\n",
      "\n",
      "Topic 0: camino, seguir, esperar, calle, decir, acercar, llevar, tipo, estar, responder, empezó, hombre, edad, pasar, poder\n",
      "Topic 1: persona, personas, situación, tipo, momento, forma, ver, evitar, situaciones, lugar, poder, profesional, necesario, tener, llegar\n",
      "Topic 2: persona, situación, personas, pensar, ayuda, estar, lugar, alguien, víctima, forma, vivir, cerca, ayudar, hacer, vida\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora\n",
    "\n",
    "# Lista de stopwords personalizada\n",
    "\n",
    "my_stopwords = [\"ir\", \"empezar\", \"micro\", \"año\", \"tipo\", \"empezar\"]\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    tokens = word_tokenize(text)\n",
    "    unigrams = [token for token in tokens if token not in stop_words and token not in my_stopwords]\n",
    "    return list(set(lemmas + unigrams))\n",
    "\n",
    "# Preprocesamiento de los documentos\n",
    "text = [preprocess(document) for document in texts]\n",
    "\n",
    "# Creación del diccionario y del corpus\n",
    "dictionary = gensim.corpora.Dictionary(text)\n",
    "corpus = [dictionary.doc2bow(text) for text in text]\n",
    "\n",
    "# Entrenamiento del modelo LDA\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=3, id2word=dictionary, passes=20)\n",
    "\n",
    "# Impresión de los tópicos\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1, num_words=15):\n",
    "    print(f'Tópico: {idx} \\nPalabras clave: {topic}\\n')\n",
    "\n",
    "for i, topic in lda_model.show_topics(num_topics=3, num_words=15, formatted=False):\n",
    "    print(\"Topic {}: {}\".format(i, \", \".join([word for word, _ in topic])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2bb5aa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópico 0:\n",
      "[]\n",
      "Tópico 1:\n",
      "[]\n",
      "Tópico 2:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "# Preprocesar los documentos\n",
    "documents = df_all[\"textos\"]\n",
    "texts = [preprocess_string(doc) for doc in documents]\n",
    "\n",
    "# Crear un diccionario de palabras\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# Crear un corpus de documentos\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Entrenar el modelo LDA\n",
    "num_topics = 3\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42)\n",
    "\n",
    "# Extraer las palabras clave para cada tópico sin repetición\n",
    "topics = lda_model.show_topics(num_topics=num_topics, formatted=False)\n",
    "for topic_id, topic in topics:\n",
    "    print(f'Tópico {topic_id}:')\n",
    "    # Obtener las palabras con una probabilidad mayor al 10%\n",
    "    words = [word for word, prob in topic if prob > 0.001]\n",
    "    # Eliminar las palabras que aparecen en otros tópicos\n",
    "    for _, other_topic in topics:\n",
    "        words = [word for word in words if word not in dict(other_topic)]\n",
    "    print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "28b272c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_0 = lda_model.show_topic(0, topn=10)\n",
    "topic_0_weighted = [(word, weight * 2 if word == 'acoso' else weight) for word, weight in topic_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0248603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('estar', 0.0014395472), ('tipo', 0.0014395429), ('hacer', 0.00126689), ('pensar', 0.0012668808), ('seguir', 0.0012668767), ('persona', 0.00126683), ('situación', 0.0012668049), ('forma', 0.0012668031), ('acoso', 0.0012667752), ('sentir', 0.0012667688)]\n",
      "[('estar', 0.0014395472), ('tipo', 0.0014395429), ('hacer', 0.00126689), ('pensar', 0.0012668808), ('seguir', 0.0012668767), ('persona', 0.00126683), ('situación', 0.0012668049), ('forma', 0.0012668031), ('acoso', 0.002533550374209881), ('sentir', 0.0012667688)]\n"
     ]
    }
   ],
   "source": [
    "print(topic_0)\n",
    "print(topic_0_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debbe22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
